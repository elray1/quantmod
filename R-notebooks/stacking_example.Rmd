---
title: "Quantile Stacking"
author: "Ryan Tibshirani"
date: "June 10, 2020"
---

```{r, include=FALSE}
knitr::opts_chunk$set(fig.width=10, fig.height=5)
```

$$
\newcommand{\argmin}{\mathop{\mathrm{argmin}}}
\newcommand{\argmax}{\mathop{\mathrm{argmax}}}
\newcommand{\minimize}{\mathop{\mathrm{minimize}}}
\newcommand{\st}{\mathop{\mathrm{subject\,\,to}}}
$$

Problem setup
===

Consider the problem
\begin{alignat*}{2}
&\minimize_\alpha \quad && 
\sum_{k=1}^r \sum_{i=1}^n w_i \psi_{\tau_k} \bigg(y_i - \sum_{j=1}^p \alpha_j q_{ijk} \bigg) \\
&\st && \sum_{j=1}^p \alpha_j = 1, \; \alpha_j \geq 0.
\end{alignat*}
Here $\tau_k$, $k=1,\ldots,r$ is a set of quantile levels, assumed to be in increasing order and each $q_{ijk}$ is an estimate of the quantile of $y_i$ at the level $\tau_k$, from ensemble component member $j$ Also, 
$$
\psi_\tau(v) = \max\{\tau v, (\tau-1) v)\},
$$
often called the "pinball" or "tilted $\ell_1$" loss, for a quantile level $\tau \in (0,1)$, and $w_i$, $i=1,\ldots,n$ are observation weights. A more flexible approach would be to estimate a separate ensemble weight $\alpha_{jk}$ per component method $j$ and quantile level $k$: 
\begin{alignat*}{2}
&\minimize_\alpha \quad && 
\sum_{k=1}^r \sum_{i=1}^n w_i \psi_{\tau_k} \bigg(y_i - \sum_{j=1}^p \alpha_{jk} q_{ijk} \bigg) \\
&\st && \sum_{j=1}^p \alpha_{jk} = 1, \; \alpha_{jk} \geq 0.
\end{alignat*}
As a form of regularization, we can additionally incorporate **noncrossing** constraints into the above optimization, which take the form:
$$
\alpha_{\bullet,k}^T q \leq \alpha_{\bullet,k+1}^T q, \; q \in \mathcal{Q}.
$$
where $\mathcal{Q}$ is some collection of points over which to enforce the constraints (for example, the training points, or the training points along with some unlabeled test points). 

LP reformulation
===

Here are the LP formulations of the two quantile stacking approaches. The standard one: 
\begin{alignat*}{2}
&\minimize_{\alpha,u} \quad && \sum_{i=1}^n w_i \sum_{k=1}^r u_{ik} \\
&\st \quad && u_{ik} \geq \tau_k \bigg(y_i - \sum_{j=1}^p \alpha_j q_{ijk}\bigg), \\ 
&&& u_{ik} \geq (\tau_k-1)\bigg(y_i - \sum_{j=1}^p \alpha_j q_{ijk}\bigg), \\
&&& \sum_{j=1}^p \alpha_j = 1 \; \alpha_j \geq 0.
\end{alignat*}
The flexible one: 
\begin{alignat*}{2}
&\minimize_{\alpha,u} \quad && \sum_{i=1}^n w_i \sum_{k=1}^r u_{ik} \\
&\st \quad && u_{ik} \geq \tau_k \bigg(y_i - \sum_{j=1}^p \alpha_{jk} q_{ijk}\bigg), \\ 
&&& u_{ik} \geq (\tau_k-1)\bigg(y_i - \sum_{j=1}^p \alpha_{jk} q_{ijk}\bigg), \\
&&& \sum_{j=1}^p \alpha_{jk} = 1 \; \alpha_{jk} \geq 0, \\
&&& \alpha_{\bullet,k}^T q \leq \alpha_{\bullet,k+1}^T q, \; q \in \mathcal{Q}.
\end{alignat*}

Poisson example
===

```{r}
library(quantmod)
n = 100
p = 50
x = matrix(rnorm(n*p), n, p)
mu = function(x) x[1] + x[2]
y = rpois(n, exp(apply(x, 1, mu)))

# Run CV for quantile lasso
tau = c(0.1, 0.3, 0.5, 0.7, 0.9)
cv_obj1 = cv_quantile_lasso(x, y, tau=tau, nlambda=30, nfolds=5, verbose=TRUE, sort=TRUE)
cv_obj2 = cv_quantile_lasso(x, y, tau=tau, nlambda=30, nfolds=5, verbose=TRUE, sort=TRUE,
                            transform=log_pad(a=1), inv_trans=inv_log_pad(a=1), jitter=unif_jitter()) 
plot(cv_obj1)
plot(cv_obj2)

# Refit a more quantile levels
tau_new = c(0.01, 0.025, seq(0.05, 0.95, by=0.05), 0.975, 0.99) 
obj3 = refit_quantile_lasso(cv_obj1, x, y, tau_new, verbose=TRUE)
obj4 = refit_quantile_lasso(cv_obj2, x, y, tau_new, verbose=TRUE)

# Generate test data 
n0 = 100
x0 = matrix(rnorm(n0*p), n0, p)
y0 = rpois(n0, exp(apply(x0, 1, mu)))

# Predicted quantiles at test points 
qpred1_init = predict(cv_obj1, x0, sort=TRUE, nonneg=TRUE, round=TRUE)
qpred1 = quantile_extrapolate(tau, qpred1_init, tau_new, qfun_left=qpois, qfun_right=qpois, nonneg=TRUE, round=TRUE)
qpred2_init = predict(cv_obj2, x0, sort=TRUE, nonneg=TRUE, round=TRUE)
qpred2 = quantile_extrapolate(tau, qpred2_init, tau_new, qfun_left=qpois, qfun_right=qpois, nonneg=TRUE, round=TRUE)
qpred3 = predict(obj3, x0, sort=TRUE, nonneg=TRUE, round=TRUE)
qpred4 = predict(obj4, x0, sort=TRUE, nonneg=TRUE, round=TRUE)

# Construct array of predicted quantiles
qarr = array(NA, dim=c(n0,4,length(tau_new)))
qarr[,1,] = qpred1
qarr[,2,] = qpred2
qarr[,3,] = qpred3
qarr[,4,] = qpred4

# Standard stacking: one weight per ensemble member
st_obj1 = quantile_ensemble(qarr, y0, tau_new, verbose=TRUE)
st_obj1$alpha

# Flexible stacking: one weight per ensemble member, per quantile level
st_obj2 = quantile_ensemble(qarr, y0, tau_new, tau_groups=1:length(tau_new), verbose=TRUE)
st_obj2$alpha

# Somewhere in the middle: group the extreme 3 quantiles together on either tail, and the middle 
st_obj3 = quantile_ensemble(qarr, y0, tau_new, tau_groups=c(rep(1,3),rep(2,17),rep(3,3)), verbose=TRUE)
st_obj3$alpha
```